<!doctype html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="widistillh=device-widistillh, initial-scale=1">
    <link rel="icon" type="image/svg+xml" href="/favicon.svg">
    <title>2. 声音的表示</title> 

    <script src="template.v2.js"></script>
</head>

<body>    
    <distill-header></distill-header>
    <d-title>
        <h1>2. 声音的表示</h1>
    </d-title>

<d-article>
    <p>
        当声音传导到我们耳中的时，声波表示空气或水中的压力变化。声波用最简单形式来表示，它就是一个一维的时间函数，f(time)。
        Fiugure-8 显示一个声波的片段。x 轴表示时间，y 轴表示声波在当前时间下的振幅（amplitude）。
        声波有时候可以是一对的，表现为立体声，甚至更多数目的声波，例如四声道声音由四个波组成。
    </p>
    <p>
        时间函数并不是表示声波的唯一方法。许多的音乐合成器和效果装置都把声波当作时间函数的，我们人类也习惯于这样思考声音。
        但是事实上，这并不是一个特别好的思考声音的方法，因为我们的大脑并没有接收声波。
    </p>
    <p><d-figure><img src="images/figure_8.png" alt="Figure 8" width="40%" /></d-figure> </p>

    <p>
        实时上，我们可以认为大脑，每时每刻，都在接收一个不同频率下振幅的数列。这个数列随着时间变化。
        举例来说，假如传入的声音存在响亮的高频，那么数列中对应那些频率的振幅值会变得更大。
        Figure-9就是一种展示方法，其中数列是图像中垂直的条带，（x 轴是时间）。这种类型的图示，称为频谱图。
    </p>

    <p><d-figure><img src="images/figure_9.png" alt="Figure 9" width="40%" /></d-figure> </p>

    <p>
        关键的问题是，声波（对任何时变的波来说，都）可以表示为无限多的正弦波之和，每个正弦波有自己的频率，幅值以及相位。
        举例来说，看看Figure-10表示的声波，它有三个虚线的正弦波组成，每个都有不同的频率。
        假如说，我们把它们加到一起，结果就是那个实线表示的更加复杂的波形。
        这些正弦波被称为 partial，在某种意义上，它们每一个都是最后波形的一部分。
    </p>

    <p><d-figure><img src="images/figure_10.png" alt="Figure 10" width="40%" /></d-figure> </p>

    <p>
        假如我们先不考虑相位，我们可以根据 Figure-11 中的每个 partial 的幅值，画出一个条形图，这时 x 轴表示频率，而不是时间。
        Figure-11就是这样的条形图。假如，我们按照这样的方式来看待声音，那么这就叫做频域描述方法（因为 x 轴表示的是频率）。
        假如，我们按照经典的方法（Figure-10），这时 x 轴表示的是时间，那么这就叫做时域描述方法。
    </p>

    <p><d-figure><img src="images/figure_11.png" alt="Figure 11" width="40%" /></d-figure> </p>

    <p>
        当一个声音任意时长和复杂的时候，用来描述这个波形的正弦波数目几乎是无限大的：所以频域图像不再是一个条状图，
        但是依然是一个频率作为参数的实数函数。举例来说，Figure-12 显示了一个贝斯吉他音符的声音时域和频域图像（实值）。
    </p>


    <p><d-figure><img src="images/figure_12.png" alt="Figure 12" width="40%" /></d-figure> </p>
    <p>
        之前就提到过，我们是在频率感知声音的世界的：这是因为我们耳内的耳蜗就是如此工作的。
        耳蜗本质上是一个长而卷曲的管子，里面装满液体并衬有绒毛。
        耳蜗起点附近的绒毛对低频声音产生交感反应，而沿着耳蜗更远的绒毛对高频声音作出反应。
        绒毛的共振频率附近的声音越大，绒毛的振动就越大。 绒毛与向大脑发送信号的神经相连。
    </p>

    <li><b>相位</b></li>
    <p>
        相位是一个正弦波开始的时间点（从0开始或者重新开始）。考虑 Figure-13 的情况，
        这张图显示了三个相同频率和振幅的正弦波，但是具有不同的相位。跟频率和振幅相比，
        一个 partial 的相位在声音中扮演关键的角色。
        因此，不应将频域视为频率与幅度的单一图，而应将其视为两个独立的图，一个是频率与幅度，
        另一个是频率与相位。 同样，构成声音的分音（partials）有两个分量：幅度和相位。
    </p>

    <p>
        相位对我们来说远没有幅度重要：人类可以更好地检测幅度。 
        事实上，虽然我们可以区分相位变化的分音，但如果我们看到两个除了相位不同之外具有相同分音的声音，
        我们将无法区分它们！ 正因为如此，一些合成方法（如<b>加法合成</b>）几乎完全忽略了相位：
        而其他一些（如<b>调频合成</b>）则非常依赖于相位的变化。
    </p>

    <li><b>谐波和音调识别</b></li>

    <p>
        大多数人类感受为“乐音”或者“音调”的声音，都由一种特定方式组织二场。在这些声音中，有一个特定的分音称为基音。
        这通常是频率最低的显著分音，通常也是最响亮的分音，并且通常他的频率会被我们会识别为这段声音的音调或者音高（pitch），
        也就是说，某一个音符。基音以外的分音称为泛音。此外，在这些“音调”声音中，大多数泛音的频率是基频的整数倍。
        也就是说，大多数泛音将具有 i x f 形式的频率，其中 f 是基频频率，并且 i 是整数 2, 3, ...。
        当分音以这种方式组织时，我们称它们为谐波（harmonics）。
    </p>

    <p><d-figure><img src="images/figure_13.png" alt="Figure 13" width="40%" /></d-figure> </p>

    <p>
        许多乐器，包括木管乐器，铜管乐器和其他弦乐器的分音主要是谐波。 
        这些乐器基本上都存在一个固定的琴弦或管子，它们只能根据某些模式振动。 考虑 Figure-14，其中小提琴弦的末端
        分别固定在 0 和 2π的位置。由于两端固定，因此小提琴弦可以振动的方式只能有限的多。
        Figure-14 显示了前四种可能性，它们的频率对应于第一种四个谐波（f、2 f、3 f 和 4 f）。 
        木管乐器类似：其管中的空气振动本质上是“固定”在两端的。
    </p>

    <p><d-figure><img src="images/figure_14.png" alt="Figure 14" width="40%" /></d-figure> </p>

</d-article>

<d-appendix> 
    <d-footnote-list></d-footnote-list>    
    <d-citation-list></d-citation-list>       
</d-appendix>

<distill-footer></distill-footer>

</body>