<!doctype html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="widistillh=device-widistillh, initial-scale=1">
    <link rel="icon" type="image/svg+xml" href="/favicon.svg">
    <title>2. 声音的表示</title> 

    <script src="template.v2.js"></script>
</head>

<body>    
    <distill-header></distill-header>
    <d-title>
        <h1>2. 声音的表示</h1>
    </d-title>

<d-article>
    <p>
        当声音传导到我们耳中的时，声波表示空气或水中的压力变化。声波用最简单形式来表示，它就是一个一维的时间函数，f(time)。
        Fiugure-8 显示一个声波的片段。x 轴表示时间，y 轴表示声波在当前时间下的振幅（amplitude）。
        声波有时候可以是一对的，表现为立体声，甚至更多数目的声波，例如四声道声音由四个波组成。
    </p>
    <p>
        时间函数并不是表示声波的唯一方法。许多的音乐合成器和效果装置都把声波当作时间函数的，我们人类也习惯于这样思考声音。
        但是事实上，这并不是一个特别好的思考声音的方法，因为我们的大脑并没有接收声波。
    </p>
    <p><d-figure><img src="images/figure_8.png" alt="Figure 8" width="40%" /></d-figure> </p>

    <p>
        实时上，我们可以认为大脑，每时每刻，都在接收一个不同频率下振幅的数列。这个数列随着时间变化。
        举例来说，假如传入的声音存在响亮的高频，那么数列中对应那些频率的振幅值会变得更大。
        Figure-9就是一种展示方法，其中数列是图像中垂直的条带，（x 轴是时间）。这种类型的图示，称为频谱图。
    </p>

    <p><d-figure><img src="images/figure_9.png" alt="Figure 9" width="40%" /></d-figure> </p>

    <p>
        关键的问题是，声波（对任何时变的波来说，都）可以表示为无限多的正弦波之和，每个正弦波有自己的频率，幅值以及相位。
        举例来说，看看Figure-10表示的声波，它有三个虚线的正弦波组成，每个都有不同的频率。
        假如说，我们把它们加到一起，结果就是那个实线表示的更加复杂的波形。
        这些正弦波被称为 partial，在某种意义上，它们每一个都是最后波形的一部分。
    </p>

    <p><d-figure><img src="images/figure_10.png" alt="Figure 10" width="40%" /></d-figure> </p>

    <p>
        假如我们先不考虑相位，我们可以根据 Figure-11 中的每个 partial 的幅值，画出一个条形图，这时 x 轴表示频率，而不是时间。
        Figure-11就是这样的条形图。假如，我们按照这样的方式来看待声音，那么这就叫做频域描述方法（因为 x 轴表示的是频率）。
        假如，我们按照经典的方法（Figure-10），这时 x 轴表示的是时间，那么这就叫做时域描述方法。
    </p>

    <p><d-figure><img src="images/figure_11.png" alt="Figure 11" width="40%" /></d-figure> </p>

    <p>
        当一个声音任意时长和复杂的时候，用来描述这个波形的正弦波数目几乎是无限大的：所以频域图像不再是一个条状图，
        但是依然是一个频率作为参数的实数函数。举例来说，Figure-12 显示了一个贝斯吉他音符的声音时域和频域图像（实值）。
    </p>


    <p><d-figure><img src="images/figure_12.png" alt="Figure 12" width="40%" /></d-figure> </p>
    <p>
        之前就提到过，我们是在频率感知声音的世界的：这是因为我们耳内的耳蜗就是如此工作的。
        耳蜗本质上是一个长而卷曲的管子，里面装满液体并衬有绒毛。
        耳蜗起点附近的绒毛对低频声音产生交感反应，而沿着耳蜗更远的绒毛对高频声音作出反应。
        绒毛的共振频率附近的声音越大，绒毛的振动就越大。 绒毛与向大脑发送信号的神经相连。
    </p>

    <li><b>相位</b></li>
    <p>
        相位是一个正弦波开始的时间点（从0开始或者重新开始）。考虑 Figure-13 的情况，
        这张图显示了三个相同频率和振幅的正弦波，但是具有不同的相位。跟频率和振幅相比，
        一个 partial 的相位在声音中扮演关键的角色。
        因此，不应将频域视为频率与幅度的单一图，而应将其视为两个独立的图，一个是频率与幅度，
        另一个是频率与相位。 同样，构成声音的分音（partials）有两个分量：幅度和相位。
    </p>

    <p>
        相位对我们来说远没有幅度重要：人类可以更好地检测幅度。 
        事实上，虽然我们可以区分相位变化的分音，但如果我们看到两个除了相位不同之外具有相同分音的声音，
        我们将无法区分它们！ 正因为如此，一些合成方法（如<b>加法合成</b>）几乎完全忽略了相位：
        而其他一些（如<b>调频合成</b>）则非常依赖于相位的变化。
    </p>

    <li><b>谐波和音调识别</b></li>

    <p>
        大多数人类感受为“乐音”或者“音调”的声音，都由一种特定方式组织二场。在这些声音中，有一个特定的分音称为基音。
        这通常是频率最低的显著分音，通常也是最响亮的分音，并且通常他的频率会被我们会识别为这段声音的音调或者音高（pitch），
        也就是说，某一个音符。基音以外的分音称为泛音。此外，在这些“音调”声音中，大多数泛音的频率是基频的整数倍。
        也就是说，大多数泛音将具有 i x f 形式的频率，其中 f 是基频频率，并且 i 是整数 2, 3, ...。
        当分音以这种方式组织时，我们称它们为谐波（harmonics）。
    </p>

    <p><d-figure><img src="images/figure_13.png" alt="Figure 13" width="40%" /></d-figure> </p>

    <p>
        许多乐器，包括木管乐器，铜管乐器和其他弦乐器的分音主要是谐波。 
        这些乐器基本上都存在一个固定的琴弦或管子，它们只能根据某些模式振动。 考虑 Figure-14，其中小提琴弦的末端
        分别固定在 0 和 2π的位置。由于两端固定，因此小提琴弦可以振动的方式只能有限的多。
        Figure-14 显示了前四种可能性，它们的频率对应于第一种四个谐波（f、2 f、3 f 和 4 f）。 
        木管乐器类似：其管中的空气振动本质上是“固定”在两端的。
    </p>

    <p><d-figure><img src="images/figure_14.png" alt="Figure 14" width="40%" /></d-figure> </p>

    <p>
        许多泛音非常接近标准音符的音高，我们对乐器的音调和它们产生的和弦的感知能力，会因此而受到很大的影响。 
        例如，频率为 2 f 的二次谐波恰好比 f 高一个八度。 三次谐波几乎比它高出五分之一。 第四谐波比基频高两个八度。 
        Figure-15 显示了基波、各种谐波、它们最接近的音符以及它们与这些音符的偏离程度。
        一些谐波非常偏离，
        <d-footnote id="1">
            您可能想知道：他们为什么偏离？传统上，音符已被调整，使得一个八度对应于频率的两倍。
            这与谐波很好地对齐，因为作为 2 的下一个幂的每个谐波都高一个八度。
            但是在一个八度范围内，其他剩余的音符如何间隔？经典的方法是假设有 12 个音符，
            它们的间隔使得任何两个连续音符（A / Ab，比如说，或 F/E）的频率之间的比率是相同的。
            这是一种奇特的分配，即音符不是按频率线性排列而是按对数排列的。这种调音策略被称为平均。
            然而，对数频率不像谐波那样沿着整数倍值排列。他们中的许多人都足够接近，但有些人离得很远。
            由于整数和对数不匹配，历史上已经提出了其他音律策略，它们会稍微调整音符以使它们听起来更和谐。
            几个世纪以来，音律策略一直是一个争论的问题。
        </d-footnote>
        但许多谐波非常接近。
    </p>

    <p><d-figure><img src="images/figure_15.png" alt="Figure 15" width="100%" /></d-figure> </p>

    <p>
        请注意，在定义基音（或者基频）术语时，我经常使用该词三次：基本通常是最低的谐波，通常是最响亮的，并且通常是决定音高的因素（从听觉上）。 
        这是因为有时其中一项或多项是不正确的。 例如，管风琴通常有一个或两个相当响亮的分音，比基本音低一个或两个八度（一个八度低对应于频率的一半）。 
        同样，钟声通常会比基音低至少一个响亮的部分，称为嗡嗡声。 
        事实上，嗡嗡声在许多方面都是基音，但我们通常将钟声中更大（通常情况下）的二次谐波（质数）识别为音高（即所谓的打击音）。因为，素数·通常被认为是基本的。
    </p>

    <p>
        
    </p>

    <p>
        钟声很奇怪。 从质数向上的下一个主要分音通常是三级音
        <d-footnote id="2">在钟声中，我们对这些不太常见的分音，称呼为：hum, prime, tierce, quint, nominal, deciem, undeciem </d-footnote>
        ，它仅比质数高出小三分之一，或大约是质数频率的 1.2 倍
        ， 是一个从质数音的小三度，或者是质数音的1.2倍频率。
        同样，在钟声钟中还存在其他一些非和谐的分音。当时，我们或多或少还是把钟声当作和谐音的。
        钟声中各种分音的特定幅度可以使我们将音高与除素数以外的分音联系起来。
        事实上，钟声可能会让我们将音高与声音中甚至不存在的分音联系起来。
    </p>

    <p>
        最后，鼓有其独特的和声特性，与弦乐或管乐完全不同。
        鼓是二维片装平面，因此其谐波振动模式（或模式）是二维的。
        这会产生一系列复杂的部分频率，如 Figure-16 所示，它们通常是无调性的
        <d-footnote id="3">  
            在一篇著名的论文中，Mark Kac 试图回答是否可以从鼓的声音来判断是否是2D的模式（ Mark Kac, 1966, Can one hear the shape of a drum?, American Mathematical Monthly, 73），
            作者花了30年来确定答案是否定的。
        </d-footnote>。
    </p>
    <p><d-figure><img src="images/figure_16.png" alt="Figure 16" width="100%" /></d-figure> </p>

    <h2>2.1 声音的度量单位</h2>

    <li><b>频率</b></li>
    <p>
        频率通常用赫兹（Hertz,HZ）来进行度量，赫兹表示一秒内正弦循环的数目。1Hz 表示完整的波需要 1 秒才能完成的正弦波。
        分音的周期是指其正弦波完成一个周期的时间量，以秒为单位。
        周期是频率的倒数：假如一个正弦循环的周期为 p ，这个正弦循环的频率是 <d-math> f = 1/p\,hz</d-math>。
    </p>

    <p>
        频率显然和音高联系在一起，表示了哪个音符在演奏。
        典型的，音高采用半音（semitones）为单位来度量，即一半的音。
        从 C 到 C# 是一个半音，就像从 G 到 G# 一样（这里 C，G 表示音名）。
        你还会看到更精细的划分：音分（cents），一音分是半音的1/100 。    
    </p>

    <p>
        音高随频率呈对数上升。当频率加倍时，我们能感知到音高上升了一个八度。
        更准确地说，如果一个音符的频率为 f ，并且我们从该音符上调 n 个半音，则新音符的频率为 <d-math> g = 2^{n/12}*f </d-math>。
        相似的，假如你从频率 f 改变到频率 g，那么相应的音高改变了 <d-math> n=12\,log_x({g/f}) </d-math>。 
    </p>

    <li><b>振幅（Amplitude）</b></li>
    
    <p> 
        当我们对幅度或音量实施乘法，使其更响亮或更柔和时，我们说我们正在改变信号的增益。
        振幅一般是正的实数值； 但通常将波形的值非正式地称为“幅度”：如果我们将波的中心置于零，它会同时高于和低于该值，因此在某些时候非正式地具有“负幅度”。
    </p>

    <p>
        信号幅度的变化，或该信号与某个参考信号之间的比率，通常以分贝 (decibels, dB) 的形式给出。 
        分贝是一种相对量度，因此您经常会看到相对于某个信号幅度的负分贝，表示声音比参考信号更安静。
    </p>

    <p>
        从分贝计算到原始幅度，或返回，并不是很难：
        假设你有两个声音 i 和 j ，它们的幅度分别为 <d-math> A_i </d-math> 和 <d-math> A_j </d-math>，
        并且声音 j 是比声音 i 高 d 个 dB ，这意味：<d-math> A_j = A_i * 10^{d/20} </d-math>。
        反过来，<d-math> d = 20\, log_{10}{\frac{A_j}{A_i} } </d-math>。 
        幅值增加一倍大约增加 6dB 。人感知的音量翻倍通常被描述为增加 10 dB。
    </p>

    <li><b>相位</b></li>
    <p>
        因为我们再讨论正弦波，一个分音的相位值是角度的度量，因此通常用<d-math>0..2\pi</d-math>来表示（当然也可以是<d-math>-\pi..\pi</d-math>。
        在 Figure-13 中，绿色和蓝色的正弦波互相之间就相差一个<d-math>\pi</d-math>的相位。
    </p>

    <li><b>立体声场</b></li>
    <p>
        当声音是立体声时，它们看起来可能来自我们的左侧、中心或右侧。 声音出现的角度位置称为声音的声相位置。
    </p>

    <h2>2.2 声波的数字化</h2>
    <p>
        声波可以（有效地）以实值形式在磁带或唱片等形式存储。但现代声音通常以数字形式存储。 
        为此，声音以均匀的时间间隔进行采样，并且每个样本（正或负）的幅度通常存储为整数。 
        因此两个地方需要进行离散化：（1）单位时间采样的数目；（2）每一个采样值的数值本身也是一个离散的整数。
    </p>

    <p>
        一个流行的方法来思考这些采样数据，就是把它们绘制在网格图上，就像 Figure-17 图示那样，
        沿着 X 轴是离散的时间值，一个采样占一个单元，从0开始递增；沿着 Y 轴是离散的幅值，取值从-1到+1。
        但是按照这种方式去想象是危险的，因为这意味着当声音采样被播放时，采用了一个横向和纵向的块状函数的形式（图中红色的线），
        而这个形式是不存在的。
    </p>

    <p><d-figure><img src="images/figure_17.png" alt="Figure 17" width="50%" /></d-figure> </p>

    <p>
        事实上，为了播放数字音频，采样会首先送入到数模转换器（DAC，Digital-Analog Converter）当中。
        DAC的工作就是将数字化的数据转换为相当平滑的模拟波形。
        因此，最好将数字化波形视为棒状图，如 Figure-17（右子图）所示。
        这有助于提醒我们，声波采样不是一堆块状线条，而实际上只是从一个实值函数（原始声音）在非常特定和精确的时间采样的数字，
        另一个实值函数可以从中采样数据中恢复构造出来。对于那些特定采样时间以外的任何时间，都没有价值：它是未定义的。
    </p>

    <li><b>采样率，奈奎斯特极限以及混叠</b></li>
    <p>
        当对声音进行采样时，采样的速度称为采样率。 n kHz 的采样率意味着每 1/(n × 1000) 秒收集或播放一个采样。
    </p>
    <p>
        数字化的声音中的n个样本，能够忠实恢复出来的最高频率是 n/2 。这个频率被称为奈奎斯特极限或者奈奎斯特频率。
        然而，用数字化的声音来绘制超高奈奎斯特频率的分音，只存在想象中。
        这些更高频率的波无法不仅表示成自己的样子，事实上它们会以低频的形式呈现出不自然的人造的分音，一种称为混叠（或折叠）的失真
        <d-footnote id="4">
            很久以前，作为一名本科生，我很明白这一点。 
            我创建了一个声音编辑器，你可以在其中将波绘制为位图，并发现如果您绘制完美的锯齿波（向上呈 45 度角，然后向下呈锐利的垂直线，并重复），
            它将生成古怪的声音。 
            这是因为可以将锯齿波存储为数字形式，但实际上这会填充超过奈奎斯特极限的分音，从而产生严重的混叠问题。
        </d-footnote>。
        一个声音（数字或者模拟的）能够被无混叠的被更高频率采样或者，我们称这样的声音是带限的，这个频率必须大于声音中最高频率的2倍。
        因此，为了防止在将声音重新采样到较低采样率时出现混叠，音频设备首先应用低通滤波器来去除所有高于奈奎斯特频率（对于新的采样率）的分音，然后再进行采样。 
        有关混叠的扩展讨论（这非常重要），请参阅第 6.2 节。
    </p>

    <p>
        理解以下关键（但非常违反直觉）的概念很重要。 
        再次考虑棒状图（Figure-17，右子图）。 该图以特定采样率 n 进行采样，因此具有 n/2 的奈奎斯特极限。 
        事实证明，只有一种模拟信号（它是带限的，截至到 n/2），正好通过这个棒状图中的点。 
        因此，这个数字棒状图代表了一个平滑的模拟信号（违反直觉）。 从数字信号中再现这种模拟信号是 DAC 的工作。
    </p>

    <li><b>常用的采样率</b></li>
    <p>
        一种常见的采样率是 44.1 kHz（即每 1/44、100 秒采样一次）：这是光盘的采样率，也是许多早期数字合成器产生的采样率。 另一种流行的速率是 48 kHz（每 1/48、000 秒一个样本）：
        这是声音制作中的常见速率：它是数字录音带的采样率，长期以来一直用于实验室环境。 第三个流行的声音产生速率是 96 kHz。
    </p>
    <p>
        为什么常见的采样率是这些数字呢？ 人类可以听到的最大频率约为 20 kHz。 
        因此，人类可感知声音的合理采样率将是至少可以容纳 20 kHz 的采样率。
        然而，为了防止混叠，录音应用程序需要在 20 kHz 处应用低通滤波器。
        低通滤波器不能精确地工作在截止频率：它们需要一定程度的频率回旋余地，因此需要奈奎斯特极限略高于 20kHz 的采样率。
        1979 年，索尼选择了 44.1 kHz，它提供了 2.05 kHz 的回旋空间，因为它与某些视频标准兼容，可以存储在早期的录像机上。
        48 kHz 也有类似的历史，源于视频标准竞争中的妥协，并最终成为视频标准。 
        现在 48 kHz 似乎更合理：它覆盖了 20 kHz，为低通滤波器提供了更大的回旋空间 (4kHz)，它可以被许多整数整除
        <d-footnote id="5">
            实际上，441000 也是公倍数 = 2^2 * 3^3 * 5^5 * 7^7 
        </d-footnote>。
        96 kHz 都是 48 kHz 的整数相关倍数。
    </p>
    
    <li><b>位宽（Bit Depth）</b></li>
    <p>
        采样率定义了数字化信号的 x 轴：位宽定义了 y 轴。 位深度决定了振幅的分辨率。 
        最常见的位宽是 16 位：也就是说，每个样本都是一个 16 位无符号整数
        <d-footnote id="6">
            当然可以使用以 0 为中心的 2 补码符号表示
        </d-footnote>。
        这意味着一个样本可以是 2^16 = 65536 个可能值中的任何一个。 
        名义中心位置是这个 (32768) 的一半； 这是典型的 0 幅度位置。 
        正弦波将在中心位置上方向上振荡，然后在中心位置下方向下振荡。
    </p>

    <p>
        你会认为小比特深度会在某种意义上产生“低分辨率”的声音，但这不是真实效果。 
        回想一下，无论位宽如何，都有一个平滑的模拟信号通过棒状图形点，DAC 将尝试重现该信号。
        相反，位宽很大程度上影响声音的动态范围：在声音被嘶嘶声淹没之前，可表示的最响亮的声音和最安静的声音之间的幅度差异。
        由于嘶嘶声过多而无法再听到安静声音的点称为本底噪声。 这也与介质的信噪比密切相关。
        更高的位宽转化为更大的动态范围。 由于这是幅度差异，因此以 dB 为单位进行测量：n 的位深度产生大约 6n dB 的差异。
    </p>

    <p>
        从这个角度来看，即使是模拟记录媒体也可以被认为具有基于其动态范围的有效“位宽”。
        黑胶唱片拥有最高的“位宽”，可以说是 10-11 位（即 60-72 dB）。 
        经典的盒式磁带在 6-9 位之间。 
        一些非常高端的磁带券可能能够达到 13-14 位以上。 
        这些都比 16 位的 CD 差很多。 
        DVD 支持 24 位的位宽！
    </p>

    <li><b>音频的压缩</b></li>

    <p>
        压缩技术在音乐合成器的开发中不会发挥太大作用，但值得一提。 
        人类的听觉系统充斥着不寻常的特征，我们可以利用这些特征去除、修改或简化声音，而且我们无法分辨出来。 
        许多早期（和当前！）声音格式中使用的一种简单策略是（companding）。 
        这利用了这样一个现象，即人类可以比不同的高音量声音更容易区分不同的柔和或中等音量声音。 
        因此，我们可以使用样本中的位进行对数编码：安静的声音比响亮的声音具有更高的分辨率。 
        应用此的早期技术通常使用 µ-law 或 a-law 压扩算法
        <d-footnote id="6">
            如果你思考一下，这些在某种意义上是一种将声音表示为浮点的方式。
        </d-footnote>。
    </p>
    <p>
        当前，更著名的是有损压缩方案，例如 MP3，它利用人类听觉中的各种偏好来剥离声音的一部分而不被检测到。 
        举一个例子，如果某个声音附近有其他频率更大的声音，人类就很难听到这个更弱的声音。
        利用这一现象，MP3 将消除那个更安静的声音，并且假设我们不会注意到的（通常事实如此）。
        MP3 通常具有固定的比特率，这意味着 MP3 为录制一秒钟的音频而消耗固定数据位数。 
        但是，如果某个声音中有很多冗余（作为一个极端的例子：完全静音的大段），
        一些压缩方案会利用这一点以不同的比特率压缩声音流的不同部分。 这些被称为可变比特率方案。
    </p>

    <li><b>声道</b></li>
    <p>
        音频大小的另一个最终因素是它占用的声道数。
        一个声道是单个声波。 
        立体声音频将由两个平行的声波组成，即两个声道。 
        Quadraphonic 声音设计用于在听众周围播放，有四个声道。 
        声道也可以提供不同的功能：例如，在电影院中，一个主要用于语音的声道直接放置到屏幕后面，
        而两个或多个声道在观众的两侧提供立体声场，而在屏幕下方的附加声道用来驱动低音炮。 
        类似的多声道格式已经进入家庭影院，例如需要六个声道的 5.1 环绕声。
    </p>
</d-article>

<d-appendix> 
    <d-footnote-list></d-footnote-list>    
    <d-citation-list></d-citation-list>       
</d-appendix>
 
<distill-footer></distill-footer>

</body>